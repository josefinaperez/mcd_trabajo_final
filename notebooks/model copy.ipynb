{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7882833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcecbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path().resolve().parents[0]\n",
    "sys.path.append(str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16383db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1db67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josefinaperez/Documents/MCD/Trabajo final/mcd_trabajo_final/venv/lib/python3.11/site-packages/sklearn/datasets/_base.py:1519: UserWarning: Retry downloading from url: https://ndownloader.figshare.com/files/5976075\n",
      "  warnings.warn(f\"Retry downloading from url: {remote.url}\")\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 207\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Area under the ROC curve : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m\"\u001b[39m % roc_auc)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtime elapsed: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m % (time() - t0))\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43mplot_species_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m plt.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mplot_species_distribution\u001b[39m\u001b[34m(species)\u001b[39m\n\u001b[32m     85\u001b[39m t0 = time()\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Load the compressed data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m data = \u001b[43mfetch_species_distributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Set up the data grid\u001b[39;00m\n\u001b[32m     91\u001b[39m xgrid, ygrid = construct_grids(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCD/Trabajo final/mcd_trabajo_final/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCD/Trabajo final/mcd_trabajo_final/venv/lib/python3.11/site-packages/sklearn/datasets/_species_distributions.py:255\u001b[39m, in \u001b[36mfetch_species_distributions\u001b[39m\u001b[34m(data_home, download_if_missing, n_retries, delay)\u001b[39m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData not found and `download_if_missing` is False\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    254\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDownloading species data from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (SAMPLES.url, data_home))\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m samples_path = \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSAMPLES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelay\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.load(samples_path) \u001b[38;5;28;01mas\u001b[39;00m X:  \u001b[38;5;66;03m# samples.zip is a valid npz\u001b[39;00m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m X.files:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCD/Trabajo final/mcd_trabajo_final/venv/lib/python3.11/site-packages/sklearn/datasets/_base.py:1513\u001b[39m, in \u001b[36m_fetch_remote\u001b[39m\u001b[34m(remote, dirname, n_retries, delay)\u001b[39m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1512\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1513\u001b[39m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:241\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    242\u001b[39m     headers = fp.info()\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "# if basemap is available, we'll use it.\n",
    "# otherwise, we'll improvise later...\n",
    "try:\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "    basemap = True\n",
    "except ImportError:\n",
    "    basemap = False\n",
    "\n",
    "\n",
    "def construct_grids(batch):\n",
    "    \"\"\"Construct the map grid from the batch object\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : Batch object\n",
    "        The object returned by :func:`fetch_species_distributions`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (xgrid, ygrid) : 1-D arrays\n",
    "        The grid corresponding to the values in batch.coverages\n",
    "    \"\"\"\n",
    "    # x,y coordinates for corner cells\n",
    "    xmin = batch.x_left_lower_corner + batch.grid_size\n",
    "    xmax = xmin + (batch.Nx * batch.grid_size)\n",
    "    ymin = batch.y_left_lower_corner + batch.grid_size\n",
    "    ymax = ymin + (batch.Ny * batch.grid_size)\n",
    "\n",
    "    # x coordinates of the grid cells\n",
    "    xgrid = np.arange(xmin, xmax, batch.grid_size)\n",
    "    # y coordinates of the grid cells\n",
    "    ygrid = np.arange(ymin, ymax, batch.grid_size)\n",
    "\n",
    "    return (xgrid, ygrid)\n",
    "\n",
    "\n",
    "def create_species_bunch(species_name, train, test, coverages, xgrid, ygrid):\n",
    "    \"\"\"Create a bunch with information about a particular organism\n",
    "\n",
    "    This will use the test/train record arrays to extract the\n",
    "    data specific to the given species name.\n",
    "    \"\"\"\n",
    "    bunch = Bunch(name=\" \".join(species_name.split(\"_\")[:2]))\n",
    "    species_name = species_name.encode(\"ascii\")\n",
    "    points = dict(test=test, train=train)\n",
    "\n",
    "    for label, pts in points.items():\n",
    "        # choose points associated with the desired species\n",
    "        pts = pts[pts[\"species\"] == species_name]\n",
    "        bunch[\"pts_%s\" % label] = pts\n",
    "\n",
    "        # determine coverage values for each of the training & testing points\n",
    "        ix = np.searchsorted(xgrid, pts[\"dd long\"])\n",
    "        iy = np.searchsorted(ygrid, pts[\"dd lat\"])\n",
    "        bunch[\"cov_%s\" % label] = coverages[:, -iy, ix].T\n",
    "\n",
    "    return bunch\n",
    "\n",
    "\n",
    "def plot_species_distribution(\n",
    "    species=(\"bradypus_variegatus_0\", \"microryzomys_minutus_0\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the species distribution.\n",
    "    \"\"\"\n",
    "    if len(species) > 2:\n",
    "        print(\n",
    "            \"Note: when more than two species are provided,\"\n",
    "            \" only the first two will be used\"\n",
    "        )\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Load the compressed data\n",
    "    data = fetch_species_distributions()\n",
    "\n",
    "    # Set up the data grid\n",
    "    xgrid, ygrid = construct_grids(data)\n",
    "\n",
    "    # The grid in x,y coordinates\n",
    "    X, Y = np.meshgrid(xgrid, ygrid[::-1])\n",
    "\n",
    "    # create a bunch for each species\n",
    "    BV_bunch = create_species_bunch(\n",
    "        species[0], data.train, data.test, data.coverages, xgrid, ygrid\n",
    "    )\n",
    "    MM_bunch = create_species_bunch(\n",
    "        species[1], data.train, data.test, data.coverages, xgrid, ygrid\n",
    "    )\n",
    "\n",
    "    # background points (grid coordinates) for evaluation\n",
    "    np.random.seed(13)\n",
    "    background_points = np.c_[\n",
    "        np.random.randint(low=0, high=data.Ny, size=10000),\n",
    "        np.random.randint(low=0, high=data.Nx, size=10000),\n",
    "    ].T\n",
    "\n",
    "    # We'll make use of the fact that coverages[6] has measurements at all\n",
    "    # land points.  This will help us decide between land and water.\n",
    "    land_reference = data.coverages[6]\n",
    "\n",
    "    # Fit, predict, and plot for each species.\n",
    "    for i, species in enumerate([BV_bunch, MM_bunch]):\n",
    "        print(\"_\" * 80)\n",
    "        print(\"Modeling distribution of species '%s'\" % species.name)\n",
    "\n",
    "        # Standardize features\n",
    "        mean = species.cov_train.mean(axis=0)\n",
    "        std = species.cov_train.std(axis=0)\n",
    "        train_cover_std = (species.cov_train - mean) / std\n",
    "\n",
    "        # Fit OneClassSVM\n",
    "        print(\" - fit OneClassSVM ... \", end=\"\")\n",
    "        clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.5)\n",
    "        clf.fit(train_cover_std)\n",
    "        print(\"done.\")\n",
    "\n",
    "        # Plot map of South America\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        if basemap:\n",
    "            print(\" - plot coastlines using basemap\")\n",
    "            m = Basemap(\n",
    "                projection=\"cyl\",\n",
    "                llcrnrlat=Y.min(),\n",
    "                urcrnrlat=Y.max(),\n",
    "                llcrnrlon=X.min(),\n",
    "                urcrnrlon=X.max(),\n",
    "                resolution=\"c\",\n",
    "            )\n",
    "            m.drawcoastlines()\n",
    "            m.drawcountries()\n",
    "        else:\n",
    "            print(\" - plot coastlines from coverage\")\n",
    "            plt.contour(\n",
    "                X, Y, land_reference, levels=[-9998], colors=\"k\", linestyles=\"solid\"\n",
    "            )\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        print(\" - predict species distribution\")\n",
    "\n",
    "        # Predict species distribution using the training data\n",
    "        Z = np.ones((data.Ny, data.Nx), dtype=np.float64)\n",
    "\n",
    "        # We'll predict only for the land points.\n",
    "        idx = (land_reference > -9999).nonzero()\n",
    "        coverages_land = data.coverages[:, idx[0], idx[1]].T\n",
    "\n",
    "        pred = clf.decision_function((coverages_land - mean) / std)\n",
    "        Z *= pred.min()\n",
    "        Z[idx[0], idx[1]] = pred\n",
    "\n",
    "        levels = np.linspace(Z.min(), Z.max(), 25)\n",
    "        Z[land_reference == -9999] = -9999\n",
    "\n",
    "        # plot contours of the prediction\n",
    "        plt.contourf(X, Y, Z, levels=levels, cmap=plt.cm.Reds)\n",
    "        plt.colorbar(format=\"%.2f\")\n",
    "\n",
    "        # scatter training/testing points\n",
    "        plt.scatter(\n",
    "            species.pts_train[\"dd long\"],\n",
    "            species.pts_train[\"dd lat\"],\n",
    "            s=2**2,\n",
    "            c=\"black\",\n",
    "            marker=\"^\",\n",
    "            label=\"train\",\n",
    "        )\n",
    "        plt.scatter(\n",
    "            species.pts_test[\"dd long\"],\n",
    "            species.pts_test[\"dd lat\"],\n",
    "            s=2**2,\n",
    "            c=\"black\",\n",
    "            marker=\"x\",\n",
    "            label=\"test\",\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title(species.name)\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "        # Compute AUC with regards to background points\n",
    "        pred_background = Z[background_points[0], background_points[1]]\n",
    "        pred_test = clf.decision_function((species.cov_test - mean) / std)\n",
    "        scores = np.r_[pred_test, pred_background]\n",
    "        y = np.r_[np.ones(pred_test.shape), np.zeros(pred_background.shape)]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, scores)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        plt.text(-35, -70, \"AUC: %.3f\" % roc_auc, ha=\"right\")\n",
    "        print(\"\\n Area under the ROC curve : %f\" % roc_auc)\n",
    "\n",
    "    print(\"\\ntime elapsed: %.2fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "plot_species_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7c62eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josefinaperez/Documents/MCD/Trabajo final/mcd_trabajo_final/venv/bin/python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
